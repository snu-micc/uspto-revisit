{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import aiohttp\n",
    "\n",
    "import logging\n",
    "import pickle\n",
    "import threading\n",
    "\n",
    "import importlib\n",
    "import file_io_utils, smiles_fetch_utils, chemspider_utils, reaction_smiles_processing_utils\n",
    "importlib.reload(file_io_utils)\n",
    "importlib.reload(smiles_fetch_utils)\n",
    "importlib.reload(reaction_smiles_processing_utils)\n",
    "\n",
    "from smiles_fetch_utils import process_batch, reprocess_no_smi\n",
    "from file_io_utils import save_smiles_dict, monitor_log, ensure_directory, add_smiles_dict\n",
    "\n",
    "\n",
    "from reaction_smiles_processing_utils import process_smiles_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = \"smiles_batches\"\n",
    "result_directory = \"result\"\n",
    "\n",
    "GPT_response_path = \"./data/GPT_response.csv\"\n",
    "GPT_response_column = \"GPT_finetuned_five\"\n",
    "GPT_response_with_smiles_path = f\"./{result_directory}/GPT_response_with_smiles.csv\"\n",
    "GPT_reaction_smiles_path = f'./{result_directory}/GPT_reaction_smiles.csv'\n",
    "\n",
    "temp_smiles_dict_json = \"smiles_dict_final_ver1.json\"\n",
    "final_smiles_dict_json = \"smiles_dict_final_updated_ver2.json\"\n",
    "log_path = 'smiles_fetch.log'\n",
    "\n",
    "ensure_directory(result_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Fetch SMILES from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_smiles_dict(df, batch_size=100, output_dir=output_directory):\n",
    "    # Ensure the output directory exists\n",
    "    ensure_directory(output_directory)\n",
    "\n",
    "    smiles_dict = []\n",
    "    semaphore = asyncio.Semaphore(60)\n",
    "    \n",
    "    # Process batches\n",
    "    for i in tqdm(range(0, len(df), batch_size), desc=\"Processing GPT Responses in Batches\"):\n",
    "        batch = df[i:i + batch_size]\n",
    "        batch_number = i // batch_size + 1\n",
    "        try:\n",
    "            temp_smiles_dicts = asyncio.run(process_batch(batch, fix_name_bool=False, semaphore=semaphore))\n",
    "            smiles_dict.extend(temp_smiles_dicts)\n",
    "            logging.info(f\"Completed batch {batch_number}/{(len(df) + batch_size - 1) // batch_size}\")\n",
    "            \n",
    "            # Save intermediate results\n",
    "            save_smiles_dict(smiles_dict, os.path.join(output_dir, f'smiles_dict_batch_{batch_number}.json'))\n",
    "\n",
    "            # Save the cache periodically\n",
    "            with open(os.path.join(output_dir, 'smiles_cache.pkl'), 'wb') as f:\n",
    "                pickle.dump(smiles_cache, f)\n",
    "\n",
    "        except Exception as e:\n",
    "            smiles_dict.extend([\"Error\"] * len(batch))\n",
    "            logging.error(f\"Error in batch {batch_number}: {e}\")\n",
    "    \n",
    "    save_smiles_dict(smiles_dict, os.path.join(output_dir, temp_smiles_dict_json))\n",
    "    return smiles_dict\n",
    "\n",
    "def run_processing():\n",
    "    make_smiles_dict(df[GPT_response_column], output_dir=output_directory)\n",
    "    logging.info(\"Processing completed\")\n",
    "    print(\"Processing completed\")\n",
    "\n",
    "async def main_reprocess():\n",
    "    semaphore = asyncio.Semaphore(40)  # Limit concurrent tasks\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        stop_event = threading.Event()\n",
    "        processing_thread = threading.Thread(target=monitor_log, args=(log_path, stop_event))\n",
    "        processing_thread.start()\n",
    "\n",
    "        await reprocess_no_smi(f'./{output_directory}/{temp_smiles_dict_json}', f'./{output_directory}/{final_smiles_dict_json}.json', session, semaphore, batch_size=100)\n",
    "        stop_event.set()\n",
    "        processing_thread.join()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing GPT Responses in Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-25 16:59:20,436 - INFO - Found SMILES for methanol from OPSIN: CO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing GPT Responses in Batches: 100%|██████████| 5/5 [02:12<00:00, 26.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing completed\n",
      "All batches processed. Stopping log monitoring.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(\n",
    "    filename= log_path,\n",
    "    filemode='w',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "df = pd.read_csv(GPT_response_path)\n",
    "\n",
    "# Create a stop event for the log monitoring\n",
    "stop_event = threading.Event()\n",
    "\n",
    "# Start the processing thread\n",
    "processing_thread = threading.Thread(target=run_processing)\n",
    "processing_thread.start()\n",
    "\n",
    "# Monitor the log in real-time\n",
    "try:\n",
    "    monitor_log(log_path, stop_event)\n",
    "finally:\n",
    "    # Once processing is done, signal the log monitoring to stop\n",
    "    stop_event.set()\n",
    "    processing_thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:   0%|          | 0/5 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-25 17:04:53,149 - ERROR - [ChemSpider] No results found for Et2O\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  20%|██        | 1/5 [00:42<02:49, 42.42s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BATCH 1] 17.25% of entries don't have a corresponding SMILES representation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  40%|████      | 2/5 [02:34<04:10, 83.44s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BATCH 2] 14.33% of entries don't have a corresponding SMILES representation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  60%|██████    | 3/5 [04:22<03:08, 94.40s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BATCH 3] 9.79% of entries don't have a corresponding SMILES representation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  80%|████████  | 4/5 [05:18<01:19, 79.29s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BATCH 4] 8.9% of entries don't have a corresponding SMILES representation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|██████████| 5/5 [07:45<00:00, 93.19s/batch] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BATCH 5] 4.46% of entries don't have a corresponding SMILES representation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run the async main function\n",
    "asyncio.run(main_reprocess())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_smiles_dict(column_name =f'{GPT_response_column}_smiles', exisitng_file_path=GPT_response_path, smiles_dict_file_path=f\"./{output_directory}/{final_smiles_dict_json}.json\", output_path = GPT_response_with_smiles_path )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Generate reaction smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: maximum recursion depth exceeded;reactant from the previous step is stated as the product in the next step\n",
      "Error: too many values to unpack (expected 2);reactant from the previous step is stated as the product in the next step\n"
     ]
    }
   ],
   "source": [
    "result_df = pd.read_csv(GPT_response_with_smiles_path)\n",
    "configs = [(GPT_response_column, GPT_response_column+'_smiles')]\n",
    "for model, smiles_col in configs:\n",
    "    responses = result_df[model].tolist()\n",
    "    smiles = result_df[smiles_col].tolist()\n",
    "    skeleton_smiles, final_smiles, skeleton_error_smiles = process_smiles_data(responses, smiles)\n",
    "\n",
    "    result_df[f'{model}_skeleton'] = skeleton_smiles\n",
    "    result_df[f'{model}_rxn'] = final_smiles\n",
    "    result_df[f'{model}_smiles'] = smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result_df.to_csv(GPT_reaction_smiles_path, encoding='utf-8-sig', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uspto_revisit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
